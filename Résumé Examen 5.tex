\documentclass[11pt, english]{memoir}

\usepackage{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[utf8]{inputenc}   % LaTeX pour les accents 
\usepackage[T1]{fontenc}      % LaTeX pour les accents 
\usepackage{icomma}
\usepackage{framed}
\usepackage{geometry}
\usepackage{graphicx}

\usepackage{enumitem}
\setlist{nosep} % or \setlist{noitemsep} to leave space around whole list
\renewcommand\labelitemi{--}


%Pour redéfinir le format des titres de sections
%\usepackage{titlesec}
%\titleformat{\subsection}{\normalfont\sffamily\bfseries\LARGE\raggedright}{\thesection}%{1em}{}
\renewcommand{\chaptitlefont}{\normalfont\scshape\bfseries\Huge\raggedright}
%Une autre option est la commande suivante
\setsecheadstyle{\normalfont\bfseries\scshape\Large}

%pour le niveau de "profondeur" de la table des matières
\usepackage{tocloft}
\setsecnumdepth{subsection}

%pour la couleur des hyperliens de la table des matières 
\usepackage[colorlinks]{hyperref}
\hypersetup{linkcolor=blue}

%Pour, entre autre, pouvoir mettre une bordure sur des équations sur plusieurs lignes 
\usepackage{tcolorbox}
\tcbuselibrary{theorems, breakable}
\tcbset{colback = white, colframe = black, arc = 0mm, breakable}


\newtheorem{definition}{définition}
\numberwithin{definition}{section} 

\newtheorem{theorem}{Théorème}
\newtheorem{conjecture}{Propriété}
\newtheorem{example}{Exemple}[section]
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remarque}

\newenvironment{proof}[1][Démonstration]{\noindent\ }{\ \rule{0.5em}{0.5em}}
\newenvironment{exemple}
{
	\begin{example} \normalfont \ \\[5pt] 
	}
	{
		\hfill\rule{0.5em}{0.5em}\end{example}
}

\newenvironment{solution}
{\noindent\textbf{Solution:} \\[5pt] 
}{
}


\geometry{headsep=15pt}
\normalsize\setlength{\parskip}{\baselineskip}
\setlength{\oddsidemargin}{25mm}
\setlength{\evensidemargin}{25mm}
\setlength{\voffset}{-1in}
\setlength{\hoffset}{-1in}
\setlength{\textwidth}{165mm}
\setlength{\topmargin}{0mm}
\setlength{\headheight}{15mm}
\setlength{\headsep}{11mm}
\setlength{\topskip}{0mm}
\setlength{\textheight}{222mm}


% Pour enlever l'INDENTATION 
\setlength\parindent{0pt}



% POUR DÉFINIR UNE NOUVELLE COMMANDE (ici l'opérateur de MOYENNE EMPIRIQUE) 
\newcommand{\mean}[1]{\bar{#1}}

\newcommand{\Var}{\text{Var}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\E}{\text{\textbf{E}}}






\begin{document}
	
	\title{\normalfont\textbf{CAS Exam 5 - Summary}}
	\author{François Déry}
	\date{}
	\maketitle
	
	{\color{black}\tableofcontents}
	
	
	\part{Ratemaking (\emph{Werner \& Modlin})}
	\chapter{Introduction}
	For every business having the goal of indefinitely operating, one should try and find the perfect balance of the following fundamental equation : 
	\begin{align*}
	\text{Price} = \text{Cost} + \text{Profit}
	\end{align*}
	For most of the non-insurance corporation, this process is relatively straight forward as they control every parameter of the equation. They can always try and reduce their production cost in order to gain profit or improve their competitiveness. The insurance market is different, as the insurer can't control their primary cost of doing business, ie the losses accompanying the insurance contracts they provide. Because of this particularity, insurers tend to write the \textbf{fundamental equation} as 
	\begin{tcolorbox}[ams align*]
		\text{UW Profit} = \text{Premium} - \text{Losses} - \text{LAE} - \text{UW Expenses}.
	\end{tcolorbox}
	Where "UW" stands for \emph{underwriting} and "LAE" stands for \emph{loss adjustment expenses}. Though out the chapter, the will be covered in more detail. 
	
	
	\section{ADD THE CAS STATEMENT'S PRINCIPLES!!!!}
	
	
	\section{Exposure \& Premium}
	
	An exposure is the basic unit of risk that underlies the insurance premium. There are four different ways to measure exposures and premiums : 
	\begin{itemize}
		\item \textbf{Written} Exposure/Premium \\
		When we are in the written basis, we refer to all exposures and premium arising from policies issued during a specific period of time.
		\item \textbf{Earned}  Exposure/Premium \\
		On a \emph{earned} basis, we refer to the portion of exposures or premiums for which the insurance coverage has been provided, as of a certain point in time. 
		\item \textbf{Unearned}  Exposure/Premium \\
		As opposed to an earned basis, on a \emph{unearned} basis, we refer to the portion of exposures or premiums for which the insurance coverage has not been provided, as of a certain point in time. 
		\item \textbf{In-force}  Exposure/Premium \\
		When we refer to in-force exposure or premiums, we refer to the exposures or premiums exposed to loss (or for which the insurance coverage is provided) at a specific point in time.   
	\end{itemize}
	
	\section{Claims \& Losses}
	The text defines a claim as the demand for indemnification under the coverage of a policy. Note that a claim can be filed by an insured or by a third party alleging injuries or damages. Associated with a claim is a loss,  which is the amount of compensation for the claim. 
	
	An insurance company usually compiles claims on one of two metrics : \textbf{accident date} (date of loss, occurrence date) or \textbf{reported date}. 
	
	Claims that have occurred but are not yet reported to the insurer constitute the \textbf{IBNR (incurred but not reported) claims}. These have to be accounted for (ie as reserve of money) when calculating the \textbf{estimated ultimate losses}, as well as the \textbf{IBNER (incurred but not enough reported) claims}. 
	
	Finally, a reported loss can always be divided into two components : the \textbf{paid loss} and the \textbf{case reserve}. The paid loss is the amount that is already paid to the claimant, and the case reserve is the best estimation of what is left to be paid in order to close the claim. 
	
	
	\begin{tcolorbox}
		We calculate the total estimated ultimate losses as : 
		\begin{align*}
		\begin{minipage}{90pt}
		\begin{center}
		\textbf{Estimated Ultimate Losses}
		\end{center}
		\end{minipage}
		&= \textbf{Reported Losses + IBNR reserve + IBNER reserve},
		\end{align*}
		where $\text{reported losses} = \sum\big(\text{individual paid losses + case reserve}\big)$.
	\end{tcolorbox}
	
	
	In addition to paying money for compensation to the claimant, an insurer also incurs expenses in the process : \textbf{Loss adjustment expenses (LAE)}. These are separated into two categories : 
	\begin{itemize}
		\item \textbf{ALAE} : Allocated loss adjustment expenses;
		\item \textbf{ULAE} : Unallocated loss adjustment expenses.
	\end{itemize}
	ALAE are expenses incurred directly attributable to a specific claim, in contrast with ULAE that are expenses incurred from the general process of settling claims (for example, salaries to pay compensation experts). By definition, we have :
	\begin{align*}
	\textbf{LAE} = \textbf{ALAE} + \textbf{ULAE}
	\end{align*}
	
	\section{Underwriting Expenses}
	Just like the insurer incurs expenses to settle claims, it also incurs expenses in its underwriting process. These are generally separated into 4 categories : 
	\begin{itemize}
		\item Commissions and brokerage;
		\item General;
		\item Taxes, licenses and fees;
		\item Other acquisition.
	\end{itemize}
	
	Commissions and taxes are self-explanatory. We define other acquisition expenses everything other than commission and brokerage expenses that are directly linked to the process of acquiring business (publicity, mailing cost, etc.). The general expenses are every costs associated with the insurance operations, for example maintenance of the company's offices. 
	
	
	\section{Prospective Ratemaking \& Experience Adjustments}
	It is common practice in ratemaking to use historical data to predict future expected costs : \emph{this does mean actuaries are setting premium to recoup past losses}, as this would contradict the first principle of the CAS's statement of principles, which is "\emph{A rate is an estimate of the expected value of future costs}".
	
	So we can use historic loss experience in the estimation of future losses. With that said, it is important to remember that adjustments are necessary for the experience to accurately  predict future losses. Namely, we have to consider these potential factors : 
	\begin{itemize}
		\item Rate changes
		\item Operational changes 
		\item Inflationary pressures 
		\item Change in the mix of business
		\item Law changes
	\end{itemize}
	
	
	
	\section{Basic Insurance Ratios}
	Here are a few basic ratios that insurers use to monitor and evaluate the appropriateness of its rates. 
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Frequency}, bottomrule = 0mm, leftrule = 0mm, rightrule = 0mm, toprule = 0mm]
		Frequency mesures the rate at which claims occur. It is calculated as :
		\begin{align*}
		\textbf{Frequency} = \frac{\textbf{Number of Claims}}{\textbf{Number of Exposures}}.
		\end{align*}
		Usually, we would use the reported claims and the number of earned exposures. Analysis of frequency models can help measure the effectiveness of underwriting actions, such as deductibles. 
	\end{tcolorbox}
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Severity}, boxrule = 0mm]
		Severity is the measure of average costs per claim, and is calculated as : 
		\begin{align*}
		\textbf{Severity} = \frac{\textbf{Losses}}{\textbf{Number of Claims}}.
		\end{align*}
		We would calculate the paid severity using paid losses on closed claims, divided by the number of closed claims, and the reported severity using reported losses and claims. ALAE can be included or excluded from calculations. \\
		
		Analysis of severity models helps the understanding loss trends. 
	\end{tcolorbox}
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Pure Premium}, boxrule = 0mm]
		\begin{align*}
		\textbf{Pure Premium} = \frac{\textbf{Losses}}{\textbf{Number of Exposures}} = \textbf{Frequency} \times \textbf{Severity}.
		\end{align*}
		Also known as loss cost or burning cost, it measures the average loss per exposure.  
	\end{tcolorbox}
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Average Premium}, boxrule = 0mm]
		\begin{align*}
		\textbf{Average Premium} = \frac{\textbf{Premium}}{\textbf{Number of Exposures}}.
		\end{align*}
		The average premium can be calculated using earned premium and exposures as well as written or in force exposure, depending on what is analyzed. Both premium and exposures have to be on the same basis. \\
		
		If adjusted for rate changes, changes in average premium highlight changes in the mix of business written. 
	\end{tcolorbox}
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Loss Ratio}, boxrule = 0mm]
		\begin{align*}
		\textbf{Loss Ratio} = \frac{\textbf{Losses}}{\textbf{Premium}}.
		\end{align*}
		A loss ratio measures the portion of each premium dedicated to paying losses. Typically, earned premiums and reported losses used. Sometimes, LAE are included in the losses, forming a loss and LAE ratio, which would be : 
		\begin{align*}
		\textbf{Loss and LAE Ratio} = \frac{\textbf{Losses} + \textbf{LAE}}{\textbf{Premium}} = \textbf{LR}(1+\textbf{LAE ratio}).
		\end{align*}
	\end{tcolorbox}
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Loss Adjustment Ratio}, boxrule = 0mm]
		\begin{align*}
		\textbf{LAE Ratio} = \frac{\textbf{LAE}}{\textbf{Losses}} .
		\end{align*}
		Usually, analysis of LAE Ratio if made to monitor the effectiveness of the claim settlement process. 
	\end{tcolorbox}
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Underwriting Expense Ratio}, boxrule = 0mm]
		If we want to calculate the underwriting expense ratio for all underwriting expenses, than we would do 
		\begin{align*}
		\textbf{UW Expense Ratio} = \frac{\textbf{Commission} + \textbf{Taxes} + \textbf{Other}}{\textbf{Written Premium}} + \frac{\textbf{General Expenses}}{\textbf{Earned Premium}}.
		\end{align*}
		
		If we want to calculate the ratio for a specific type of underwriting expense, it is important to note that the basis of premiums will depend on the type of underwriting expenses analyzed. In general, the ratio is
		\begin{align*}
		\textbf{UW Expense Ratio} = \frac{\textbf{UW Expenses}}{\textbf{Premium}} .
		\end{align*}
		\begin{itemize}
			\item For commissions, other acquisitions and taxes, we use \emph{written premiums}, the reasoning being that no matter if the policies remains in force the total duration of its term, we will pay those expenses in full. Hence the use of written premiums.
			\item For general expenses, we use \emph{earned premiums}, since you want to evaluate theses expenses with the amount of premiums the company is actually earning. 
		\end{itemize}
	\end{tcolorbox}
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Operating Expenses Ratio (OER)}, boxrule = 0mm]
		\begin{align*}
		\textbf{OER} = \textbf{UW Expense Ratio} + \frac{\textbf{LAE}}{\textbf{Earned Premiums}} .
		\end{align*}
		This ratio measures the overall portion of premiums used to pay for all the company's expenses except the actual losses coming from claims. \\
		
		It's important to note that in this definition, earned premiums are used in the calculation of the underwriting expense ratio. 
	\end{tcolorbox}
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Combined Ratio}, boxrule = 0mm]
		\begin{align*}
		\textbf{Combined Ratio} = \textbf{Loss Ratio} + \frac{\textbf{Underwriting Expenses}}{\textbf{Written Premiums}} + \frac{\textbf{LAE}}{\textbf{Earned Premiums}} .
		\end{align*}
		If we were to use earned premiums instead of written premiums in the underwriting expense ratio, we could also write the combined ratio as 
		\begin{align*}
		\textbf{Combined Ratio} = \textbf{Loss Ratio} + \textbf{OER}.
		\end{align*}
		In calculating the combined ratio, the loss ratio should not include LAE, since we would consider theses expenses twice. Obviously, you always want a combined ratio under 100\%, otherwise you are losing money in operating the business. 
	\end{tcolorbox}
	
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Renewal/Retention Ratio}, boxrule = 0mm]
		Retention and renewal ratios are the rate at which insureds renew their policies. There are a small difference in their definition. We define a renewal ratio as 
		\begin{align*}
		\textbf{Renewal Ratio} =  \frac{\textbf{Number of Policies Renewed}}{\textbf{All expiring written policies}}.
		\end{align*}
		A renewal ratio doesn't take into account cancellations of policies during their term, it only looks at how many policies renewed from the pool of policies that would have come to expire. As opposed to that, a retention ratio is defined as 
		\begin{align*}
		\textbf{Retention Ratio} = \frac{\textbf{Number of Policies Renewed}}{\textbf{Number of Potential Renewal Policies}}.
		\end{align*}
		As we can see, a retention ratio only takes into account policies which were available for renewal, hence not considering policies that canceled their coverage during their term. It is a conditional version of a renewal ratio
	\end{tcolorbox}
	
	
	\begin{tcolorbox}[adjusted title = \textbf{Close Ratio}, boxrule = 0mm]
		\begin{align*}
		\textbf{Close Ratio} = \frac{\textbf{Number of Accepted Quotes}}{\textbf{Number of Quotes}}.
		\end{align*}
		The close ratio measures the competitiveness of the company's rates on the market for new business. 
	\end{tcolorbox}
	
	
	
	
	\chapter{Rating Manuals}
	
	\chapter{Ratemaking Data}
	
	\section{Data Aggregation}
	In order to perform ratemaking analysis, policy, claims and accounting data must be aggregated. There are three general abjectives when aggregating : 
	
	\begin{enumerate}
		\item Accurately match losses and premium for the policy
		\item Use the most recent data available
		\item Minimize the cost of data collection and retrieval
	\end{enumerate}
	
	There are four common methods of data aggregation : calendar year, accident year, policy year and reported year. 
	
	\subsection{Calendar year}
	This method considers all premium, exposure and loss transaction that occur during a twelve month calendar year, \emph{without regard to the effective date of policy insurance, the accident date or the report date of the claim}. Hence, at the end of the calendar year, earned premiums and exposures are fixed (since all future premiums and exposure will be earned in the next calendar year). 
	
	For reported loss, when aggregating in calendar year they are equal to all losses paid during the twelve month period, plus the change in case reserve. In math, it looks like : 
	\begin{align*}
	\text{Reported Losses} = \text{Paid Losses} + (\text{Case Reserve}_{fin} - \text{Case Reserve}_{ini})
	\end{align*}
	
	
	\textbf{Advantages} of the method are :
	\begin{enumerate}
		\item Data is available as soon as the calendar year ends;
		\item Very few cost of collection and retrieval. 
	\end{enumerate}
	
	\textbf{Disadvantages} of the method are : 
	\begin{enumerate}
		\item There is a time mismatch between premiums and losses, as losses may include payment and reserve changes from policies issued years ago. 
	\end{enumerate}
	
	One would use calendar year for lines of business with relatively quick loss developments. 
	
	
	\subsection{Accident year}
	Using this aggregation, premiums and exposures follow the same logic as in a calendar year aggregation ; the difference comes in the aggregation of losses. Whereas in calendar year you would only compiled losses that were incurred during the year, in accident year losses are always associated with their respective accident year. So if an accident happens in 2017, losses from this specific event will always be counted in the losses of the 2017 calendar year. This difference makes it so that losses are not set at the end of a calendar year, as they are likely to develop further in time.
	
	\textbf{Advantages} of the method are :
	\begin{enumerate}
		\item Better match between premiums and losses, as premiums earned during a calendar year are compared to losses that occurred in the same year;
		\item Few cost of collection and retrieval.
	\end{enumerate}
	
	\textbf{Disadvantages} of the method are : 
	\begin{enumerate}
		\item Since losses can develop at the end of the year, their development has to be estimated. The other option would be to wait for the development to end, which would take way to much time in certain line of business. 
		\item As a consequence of the first disadvantage, statistics from a calendar year are bound to evolve as losses from that year develop. 
	\end{enumerate}
	
	
	
	\subsection{Reported year}
	This method works exactly the same as accident year, with one small difference. Instead of using the accident year, the reported year of claims is used to aggregate losses. This is primarily used for commercial line products while using claims-made policies. Other that that, it has the same advantages and disadvantages as accident year aggregation.. 
	
	
	
	\subsection{Policy year}
	Also known as underwriting year, this method considers all premiums and losses associated with policies written during a twelve-month period. So all the premiums, exposures and losses of a policy written on December 30th 2017 would be considered in the year 2017, even though most (almost all) of its premiums would be earned in the calendar year 2018. 
	
	This specificity makes this method the best at matching premiums and losses, as they are always associated with each other. On the other hand, it also makes it the slowest to develop, since premiums from the policy year 2017 wont be fully earned until December 31th 2018, 24 months after the start of the policy year. 
	
	\textbf{Advantages} of the method are :
	\begin{enumerate}
		\item Best match possible between premiums and losses
	\end{enumerate}
	
	\textbf{Disadvantages} of the method are : 
	\begin{enumerate}
		\item Data takes 24 months from the start of the policy year to be fully available. 
		\item Losses development has to be taken into account, so results from a policy year are bound to evolve until losses from the policy year are done developing. 
	\end{enumerate}
	
	
	
	
	
	
	
	
	
	
	
	\chapter{Exposures}
	
	\section{Criteria For Exposure Bases}
	A good exposure base should meet the three following criteria :
	\begin{enumerate}
		\item Being \textbf{directly proportional to the expected loss};
		\item Be \textbf{practical};
		\item Consider \textbf{preexisting exposure base and historical data}.
	\end{enumerate}
	
	\subsection{Proportional to Expected Loss}
	All else being equal, the expected loss of a policy with two exposures should be twice as high as the one of a one exposure policy. In general, the factor with the most direct relationship to the losses is used as the exposure base. 
	
	For example, for home insurance, the expected loss of a home insured for two years is twice the expected amount of the same home insured one year. We could say that the expected losses also vary with the value of a home, but while a 200 000\$ home has higher expected losses, it's nor necessarily twice as high as a 100 000\$ home. Hence, the number of house year is selected as exposure base, while the home's value is used as a rating variable.  
	
	\subsection{Practical}
	The exposure base should be objective and relatively easy to obtain and verify. It should not allow for moral hazard from policyholders or underwriters (manipulating the exposure base for their own benefit). 
	
	For example, in auto insurance, the exposure base being the most proportional to expected losses is the yearly mileage of the vehicle. That being said, it's very hard for insurers to verify without reasonable doubt (although the technology is getting there). Hence, the most practical exposure base is still the vehicle year. 
	
	\subsection{Historical Precedence}
	Any changes to the exposure base can lead to large premium swings for individual insureds and requires major changes in the rating algorithm. Also, the company might not have the historical data in order to use its experience in the ratemaking process. 
	
	\subsection{Common Exposure Bases by Line of Business}
	Here are the most used exposure bases by line of business. 
	
	\begin{tabular}{ll}
		\toprule[1pt]
		\textbf{Line of Business} & \textbf{Typical Exposure Base}\\
		\midrule[1pt]
		Personal Automobile & Earned Car Year\\
		Homeowners & Earned House Year \\
		Workers Compensation & Payroll \\
		Commercial General Liability & Sales Revenue, Payroll, Square Footage, Number of Units\\
		Commercial Business Property & Amount of Insurance Coverage \\
		Physician's Professional Liability & Number of Physician Year \\
		Professional Liability & Number of Professionals (ex: Lawyers, Accountants, etc.)\\
		Personal Articles Floaters & Value of Item\\
		\bottomrule[1pt]\\
	\end{tabular}
	
	
	
	\section{Aggregation of Exposures (One-year Policies)}
	When aggregating exposures, only two methods are applicable : calendar and policy year. Here is how one would aggregates the different types of exposures (written, earned, in-force) using both methods. 
	
	\subsection{Written Exposures}
	
	Written exposures are the total exposures arising from policies written during the period. For example, if a one-year policy is written on May 21st 2017, this would count as one exposure in calendar year 2017 and policy year 2017. The difference between the two methods of aggregation comes with cancellations of policies. For example, let consider a one-year policy written on June 30th 2017 that canceled on April 1st 2018. 
	
	When working in \textbf{policy year}, we would book both the original written exposure and the exposure due to cancellation in 2017. At the end of the policy year, this policy would account for $(1-\frac{\text{3 remaining months}}{\text{12 months}}) = \frac{9}{12}$ exposure.
	
	In contrast, when working in \textbf{calendar year}, the original written exposure and the exposure due to cancellation would not be booked in the same year, since the events didn't happen in the same calendar year. So this policy would account for 1 exposure in 2017 and $(-\frac{\text{3 remaining months}}{\text{12 months}}) = -0.25$ exposures in 2018. 
	
	
	\subsection{Earned Exposures}
	Earned exposures represent the portion of the written exposures for which the insurance coverage has already been provided. Usually, we assume that the probability of claims is evenly distributed throughout a year, so that we can use the portion of time that passed since writing of the policy as a basis. 
	
	For \textbf{policy year}, earned exposures are easy. Assuming that the policy year is completed, earned and written exposures are the same, since they are both counted in the same year. If the policy year isn't over when calculations occur, than we would use the portion of time that passed since the writing of the policy as earned exposures. For example, if calculations of earned exposure for policy year 2017 were made on June 30th 2018, a one-year policy written on October 1st 2017 would have 9/12 exposures.
	
	For \textbf{calendar year}, things are a little more complicated. We should only consider the exposure earned in the calendar year. So for the same one-year policy written on October 1st, we would only count the exposure in the months of October, November and December as earned in 2017. The rest of the exposure would be counted in 2018. Obviously, earned exposures are rarely the same as written exposures for a specific policy. 
	
	
	
	\subsection{In-Force Exposure}
	These exposure counts the number of insured risk that are exposed to claiming at a specific point in time. On a typical exposure graph (with time a X-axis and \% of policy term expired on the Y-axis) then we'd count all the policies that cross a straight vertical line at a given point 
	
	
	\section{Aggregating With Other Policy Terms}
	All of the preceding definition and examples were based on one-year policies, but in reality terms can be longer or shorter that a year. Assuming we are working with a policy-year base exposure, here are the main adaptation made when working with other terms : 
	\begin{itemize}
		\item When working with \textbf{written} exposures, all of the policies represent one-half of the written exposure of a one-year policy. Hence, a 6 months policy would represent 0.5 exposure and a two-year policy would be 2 exposures. \\
		\item For \textbf{in-force} exposures, each policy can contribute to \emph{one in-force exposure}, no matter the policy term. 
	\end{itemize}
	
	\section{Calculation of Blocks of Experience}
	Companies don't always have detailed information about policies. For example, they might have the informations summarized on a monthly or quarterly basis. When such a situation happens, insurers usually work as if \emph{all policies were written on the mid-point of the period}. This is a good approximation only when policies are written evenly throughout the period. Hence, the shorter the period, the more likely this assumption is accurate. 
	
	As a quick example, if informations are summarized by month, we would assume that all of the policies written in that month were effective on the 15th of that month. 
	
	Since the assumption is that all policies for a given month are written on the 15th of that month, the written exposures for annual policies will be earned over a 13 month period. That is because there is always a half-month still to be earned after 12 months, coming from the fact that we started on the 15th.
	
	Other than that distinction, the same principles of aggregation covered previously apply.
	
	
	
	
	\chapter{Premiums}
	The process of ratemaking usually takes into account historical premium, but in order to do that several adjustment have to be applied. More specifically : 
	\begin{itemize}
		\item Bring historical premiums to the rate currently in effect;
		\item Develop premiums to ultimate levels, if it is still evolving; 
		\item Project historical premiums to the premium level in effect in the future. 
	\end{itemize}
	
	But first, just like exposures, let's review ways of aggregating premiums. As the procedure is really similar, we focus on the differences. 
	
	\section{Premium Aggregation}
	\subsection{Written Premiums}
	In principle, it's the same as exposure : all premium written in calendar or policy year counts in that specific year. The only difference is again when policies are canceled. When dealing with cancellation in calendar year, we subtract the proportion of written premium that was left to be paid in that calendar year. 
	
	For example, when writing a policy on July 1st 2017 for 900\$, we have 900\$ of written premium in the calendar year 2017. If the policy was to be canceled on April 1st 2018, we would subtract $ 900(1 - 2/3) = 300 $\$ from the written premiums of calendar year 2018. In policy year, we would subtract from policy year 2017.
	
	Of course, as with exposures we have 
	\begin{align*}
	\text{Written Premium} = \text{Earned Premium} + \text{Unearned Premium}.
	\end{align*} 
	
	\subsection{Earned Premiums}
	It works exactly as exposure. The only difference is that instead of calculating the portion of a policy's written exposure, we take the portion of its written premium earned in a specific calendar or policy year. 
	
	\subsection{In-Force Premiums }
	In-force premiums of a company represents the total amount of full-time premium for all policies in effect at a given time. This metric should be interpreted with care when comparing two portfolios with written policies on different terms. For an insurer that writes half-year policies would have half of the in-force premiums as the same insurer writing one-year policies (even though after a year, they both could have the same earned exposure). 
	
	\subsection{Calculation of Blocks of Policies}
	Works the same as with exposures. If we have aggregated data by period, it is customary for an insurer to assume all of the policies were written on mid point of the period. With that, you can calculate written, earned and in-force premiums. 
	
	
	\section{Adjustment To Premium : Extension of Exposures}
	This method involves rerating every policy from the historical data to restate historical premium to the amount that would be charged under the current rates. 
	
	It is obviously the most accurate current rate level method, but it requires detailed data and good computing power. Also, actuaries must have all of the applicable rating characteristics for every policy in the historical period. 
	
	\section{Parallelogram Method}
	See Werner \& Modlin manual, page 74 to page 80 for full details. 
	
	This method assumes that premium is written evenly throughout the time period. It adjusts\emph{ the aggregated historical premium} by an average factor to bring the premiums on-level with the current rates. 
	
	As premiums are aggregated, we calculate the on-level premiums by aggregate group (calendar year, policy year, etc.). The method differs in the calculations depending on the method of aggregation, but the logic is the same. 
	
	Here are the general steps of the parallelogram method :
	\begin{tcolorbox}
		\begin{enumerate}
			\item For each rate change, calculate the cumulative index (taking in consideration all of the previous rate changes). For example :  
			
			\begin{tabular}{cccc}
				\toprule
				Rate Level Group & Effective Date & Rate Change & Cumulative Index \\
				\midrule
				1 & Initial & 0\% & 1 \\
				2 & 07/01/2010 & 5\% & 1.05\\
				3 & 01/01/2011 & 10\% & 1.155\\
				4 & 04/01/2012 & -1\% & 1.143\\
				\bottomrule
			\end{tabular}  \\
		
			\item  Calculate the proportion of the aggregated exposure of the period that correspond to each rate level group. This can usually be done geometrically. 
			\item With each of the proportion, calculate the weighted average cumulative index for the period, like this (if you don't know how to do a weighted average) :
			 \begin{align*}
			 \text{Average Cumulative Index} = \sum_{i = 1}^{n} (\text{Proportion}_{i})(\text{Cumulative index}_{i})
			 \end{align*}
			\item The on-level factor is 
			\begin{align*}
			\text{On-Level Factor} = \frac{\text{Current Cumulative Rate Level Index}}{\text{Average Rate Level Index}}.
			\end{align*}
			\item the On-Level Premium for the aggregated period is 
			\begin{align*}
			\text{On-Level Premium} = \text{Aggregated Premiums} * \text{On-Level Factor}.
			\end{align*}
		\end{enumerate}
	\end{tcolorbox}
	
	
	\begin{exemple}
		CAS Exam 5, Fall 2013 Question \#2 :\\
		All policies have 6-months terms, and are written evenly throughout the year. The rating algorithm is $ (\text{Base rate}*\text{Class Factor} + \text{Fees}) $, ans the current rates are :
		
		\begin{tabular}{lc}
			Base Rate & 500\$ \\
			Class A Factor & 1.00 \\
			Class B Factor & 0.80 \\
			Fees & 55\$
		\end{tabular}\\
	
		Here is the distribution of exposures for different underwriting period : 
		
		\begin{tabular}{cccc}
			\toprule
			Period & Effective Date & Class A written exposures & Class B written exposures \\
			\midrule
			1 & 01/01/2011 - 06/30/2011 & 125 & 50 \\
			2 & 07/01/2011 - 12/31/2011 & 150 & 100 \\
			3 & 01/01/2012 - 06/30/2012 & 175 & 150 \\
			4 & 07/01/2012 - 12/31/2012 & 200 & 200 \\
			\bottomrule
		\end{tabular}\\
		
		Using the Extension of Exposures method, calculate the on-level earned premium for calendar year 2012.
		 
		\begin{solution}
			As we have exposures from 6-months period, we will choose the average written date as evaluation point and assume that the exposures are evenly written. From the evaluation point, we calculate the portion of the period that is earned in calendar year 2012. So we have : 
			
			\begin{tabular}{ccccc}
				\toprule
				Period & Mid Point & \% Earned in 2012 & Class A exposures & Class B exposures \\
				\midrule
				1 & 04/01/2011 & 0\% & 125 & 50 \\
				2 & 10/01/2011 & 50\% & 150 & 100 \\
				3 & 04/01/2012 & 100\% & 175 & 150 \\
				4 & 10/01/2012 & 50\% & 200 & 200 \\
				\bottomrule
			\end{tabular}\\
		
		Now that we know \% of exposure earned in 2012 for each period, we can calculate the aggregate earned exposure for calendar year 2012 and each class.
		\begin{align*}
		\text{Class A}: \ & 0(125) + 0.5(150) + 1(175) + 0.5(200) = 350 \text{ Earned Exposures} \\
		\text{Class B}: \ & 0(50) + 0.5(100) + 1(150) + 0.5(200) = 300 \text{ Earned Exposures}
		\end{align*}
		 
		 With the earned exposures per class, we can now calculate the on-level earned premium : 
		\begin{align*}
		\text{Class A}: \ & (500*1.00 + 55)(350) = 194250\$ \\
		\text{Class B}: \ & (500*0.80 + 55)(300) = 136500\$
		\end{align*}
		
		Meaning that, for calendar year 2012, there are $ 194250 + 136500 = \fbox{330750} $ earned premium.
		\end{solution}
	\end{exemple}
	
	\begin{exemple}
		CAS Exam 5, Fall 2015 Question \#1 : \\
		For a book of 6-months policies that uses vehicle-year as its exposure base, the premium per vehicle is 500\$ per 6-months, for all policies effective before August 31st 2014. We have the following data: 
		
		\begin{tabular}{cc}
			\toprule
			Effective date & \# of vehicle written on this date\\
			\midrule
			02/01/2013 & 1100\\
			08/01/2013 & 800 \\
			02/01/2014 & 600 \\
			08/01/2014 & 300
		\end{tabular}
	
	Knowing a rate change is effective on September 1st 2014, calculate : 
	\begin{enumerate}
		\item the written and earned exposures for calendar year 2014
		\item the on-level earned premiums for calendar year 2014, using extension of exposures and parallelogram method. 
	\end{enumerate}

	\begin{solution}
		\textbf{\#1 -  Written and Earned Exposures for Calendar Year 2014:}
		
		\begin{tabular}{ll}
			Written exposures : & $ 0.5(600) + 0.5(300) = 450 $\\
			Earned exposures : & $ \frac{1}{6}(0.5)(800) + 0.5(600) + \frac{5}{6}(0.5)(300) = 491.66 $
		\end{tabular}
	
		\small *Note that we are multiplying by 0.5 because the exposure base is vehicle-year, while we are working with 6-months policies .\normalsize
		
		\textbf{\#2 - Extension of exposures method: }\\[0pt]
			There is a subtle detail in the question that is quite important. We are given that the premium per vehicle on a \textbf{6-months term} is 500\$, but the exposure base is the vehicle-\textbf{year}. Hence, the premium for a full-year vehicle is $ 500(2) = 1000\$ $. As we calculated the earned exposure on a vehicle-year basis in \#1, we need to have a year-base premium to calculate the earned premium. 
			
			With that said, to calculate the on-level premium, we re-rate all the policies. That means rating all 491.66 earned premium according to the -18\% rate change that occurred on September 1st. Hence, we have : 
			\begin{align*}
			\text{On-Level Premiums} &= 1000(1-0.18)491.66\\
			&=\fbox{403 169 \$}
			\end{align*} 
			
		\textbf{\#2 - Parallelogram method : } \\[0pt]
			When using this method, we have to assume that the policies were written evenly throughout time, even though in this case we know it to be false. 
			
			As policies have a 6-months term and the rate change is effective on September 1st, we have 1/9 of the policies written in calendar year 2014 that are on the new rates. Calculations goes as follow : 
			\begin{align*}
			\text{Average cumulative index} &= 1/9(1-0.18) + 8/9 = 0.98\\
			\text{On-Level factor} &= \frac{0.82}{1/9(1-0.18) + 8/9} = \frac{0.82}{0.98} = 0.836739\\
			\text{On-Level Premium} &= 0.836739(491.66)(1000\$) = \fbox{411 394 \$}
			\end{align*}
	\end{solution}
	\end{exemple}
	
	\section{Premium Development}
	Premiums might have to be developed in order to have an accurate ratemaking process. For example, is an actuary performs analysis on a policy year before all the policies written in that year have expired, than the actuary does not know which policies may still change or cancel during their remaining life. 
	
	Another example is when the the total exposure for a period can change. Let's say the insured pays premium based on an estimate or the total exposure. Once the policy is completed and the actual exposure is known, the final premium owed is calculated. This happens a lot is \textbf{workers compensation}. 
	
	\section{Exposure trend}
	For business line that use inflation-sensitive exposures bases, it is common practice to project exposures (and thus premiums) to account for future inflation. 
	
	\section{Premium trend (One/Two-Step Trending)}
	In addition to inflationary pressures, the average premium can change over time due to changes in the characteristics of the policies written (distributional changes). To account for future distributional changes, we also have to adjust the historical on-level premium to the level expected during the future time period. \textbf{Note that one should always start with the on-level premiums before adding any trend, as we don't want to include rate changes in the trend factor}.
	
	THIS IS NOT THE SAME AS ADJUSTING TO CURRENT RATE LEVEL. The premium also have to be adjusted to reflect any premium trend. 
	
	Typically, actuaries examine changes in the historical \emph{average} premium per exposure to determine the premium trend. 
	
	Trends can be determined using written or earned premiums ; written exposures tend to reflect shifts in the distribution faster than earned premium, but both are valid. The more granular the data used (for example quarterly instead of annual premium), the more responsive will be the statistic. 
	
	After determining the premium trend factor, there are two methods for adjusting historical data : \textbf{one-step} and \textbf{two-step} trending. 
	
	\subsection{One-Step Trending}
	If we think that the historical trend we stay the same in the future rate effective period, then we would use one-step trending. 
	
	We have to determine the length of time to trend the earned premiums of the historical period. The trend period is always defined the same : 
	
	\begin{tcolorbox}
		\begin{tabular}{ll}
			\textbf{From} : & 	\begin{minipage}{0.8\linewidth}
				Average WRITTEN date of the policies that have earned premiums in the historical period.
			\end{minipage}\\[15pt]
			\textbf{To} : & \begin{minipage}{0.8\linewidth}
				Average WRITTEN date of the policies that will be in effect during the rate effective period.
			\end{minipage}\\ 
		\end{tabular}\\
	
		Depending on if the historical period is aggregated by calendar or policy year, the "from" date will change. \textbf{Always refer to the definition}. The "to" date will stay the same, as the rate effective period is always in policy year. 
	\end{tcolorbox}
	
	The length of the period is obviously the difference between the "to" date and the "from" date. To calculate the trended on-level historical premiums, the calculation is : 
	\begin{tcolorbox} [ams align*]
	\textbf{Trended On-Level Premium} = (\text{On-Level Premium})(\text{Trend Factor})^{\text{(length of trending period)}}
	\end{tcolorbox}
	
	
	
	
	\subsection{Two-Step Trending}
		We would use two-step trending when we expect the premium trend to change over time, meaning that the historical trend won't necessarily apply to the future rate effective period.
		\begin{enumerate}
			\item \textbf{Step \#1 :} \\[10pt]
			We first adjust historical on-level premiums to the average premium level of \textbf{the most recent period in the historical data} (it can be a quarter, it doesn't have to be a full year). Usually, this is done by calculating the \emph{current trend factor}, which is 
			
			\begin{align*}
			\textbf{Current Premium Trend Factor} = \frac{\text{Latest Average WRITTEN on-level premium}}{\text{Historical average EARNED on-level premium}}.\\
			\end{align*}
			This trend factor brings the historical premium to the \textbf{Average WRITTEN date of the latest period of the data}, which is where the step \#2 starts. \\
			
			\footnotesize**When the historical average premium is volatile, the actuary can also choose to evaluate a trend based on several points rather than to use the previous ratio. If this method is used, the trending factor is determined just like one-step trending. The \emph{from date} would be the average written date of the policies that have earned premiums in the period, while the \emph{to date} is the average written date of the latest period.\normalsize\\
			
			
			\item \textbf{Step \#2 :}\\[10pt]
			We apply a \textbf{future trend factor} to project the premium calculate in step \#1 to the future rate effective period. This future trend factor is applied over a trending period, which is defined as : \\
			
			\begin{tabular}{ll}
				\textbf{From} : & 	\begin{minipage}{0.8\linewidth}
					Average WRITTEN date of the \textbf{latest period} of the trend data.
				\end{minipage}\\[10pt]
				\textbf{To} : & \begin{minipage}{0.8\linewidth}
					Average WRITTEN date of the policies that will be in effect during the rate effective period.
				\end{minipage}\\ 
			\end{tabular}
			
			Finally, the final trended on-level premium is calculated like this :
			\begin{align*}
			\textbf{Trended On-Level Premium} = \  &\text{On-Level Premium} \times\text{Current Trend Factor}\\
			&\times(\text{Future Trend Factor})^{\text{(length of trending period)}}
			\end{align*}
		\end{enumerate} 



	
		\begin{tcolorbox}[adjusted title = \textbf{SHORCUT}]
			When using two-step trending, a shortcut can usually be applied, coming from the definition of trended on-level premium. If we define $ n $ as the length of the future trending period, and we say that all of the premium in the calculation below are on-level, then we can say:
			\begin{align*}
			\text{Trended EP} 
				&= (\text{EP})_{\text{Histo}} \times (\text{Current Factor}) \times (\text{Future Factor})^{n} \\
				&= (\text{EP})_{\text{Histo}} \times \frac{(\text{Avg WP})_{\text{Latest}}}{(\text{Avg EP})_{\text{Histo}}} \times (\text{Future Factor})^{n}\\
				&=  (\text{EP})_{\text{Histo}} \times \frac{(\text{Avg WP})_{\text{Latest}}}{\frac{(\text{EP})_{\text{Histo}}}{(\text{Earned Exp})_{\text{Histo}}} } \times (\text{Future Factor})^{n}
			\end{align*}
			This means that we can write the trended earned premium as 
			\begin{align*}
			\textbf{Trended EP} 
				&=  (\textbf{Earned Exp})_{\textbf{Histo}} \times (\textbf{Avg WP})_{\textbf{Latest}} \times (\textbf{Future Factor})^{n}
			\end{align*}
			This shortcut is particularly useful, since it means we don't have to calculate the on-level historical premiums to calculate the trended on-level premiums. Of course, \emph{the latest average written premium must be at current rates level}. 
		\end{tcolorbox}
	
	
	
	
	
	
	
	
	
	
\chapter{Losses and ALAE}


\section{Excess Losses}

Generally, actuaries remove excess losses and catastrophes from the data and replace them with a loading factor, because those types of losses tend to bring distortion to the data. Indeed, as they are very low in frequency and high in severity, they tend to worsen results of years where those types of events happen. 

The excess loss loading for a loss threshold $ d $ is defined as 
\begin{align*}
\text{Excess Loss Factor} = \frac{\sum_{i= 1}^{n}(\text{Excess Losses})_{i}}{\sum_{i = 1}^{n}(\text{Non-Excess Losses})_{i}},
\end{align*}
where
\begin{itemize}
	\item $ n $ : Total number of years in the data;
	\item Excess Losses : Part of losses in excess of the loss threshold $ d $;
	\item Non-Excess Losses : Limited Losses at the loss threshold $ d $
\end{itemize}









	
	
\chapter{UW Expenses Ratios}	

In order to calculate an indicated rate or rate change, we need to take into account underwriting expenses, more specifically how much of the premiums is used up to account for those expenses. Since there is variable and fixed underwriting expenses, we will need a ratio for both types.

\section{Variable Expense Ratio}

	This ratio evaluates the ratio of variable expenses to premiums. Just like in the definition of the underwriting expense ratio (in chapter 1), the type of premium used depends on the type of expense. We remember that except for general expenses which uses earned premiums for the ratio, all other type of expenses uses written premiums. 
		
	If we assume that all of commissions and taxes are variable, we would calculate the variable expense ratio as :
	\begin{equation*}
		\textbf{Variable Ratio} = \frac{\textbf{Commis} + \textbf{Taxes} + (\textbf{Variable \% )(Other)}}{\textbf{Written Premium}} +\frac{\textbf{(Variable \%)(General)}}{\textbf{Earned Premium}} 
	\end{equation*}
	
	IMPORTANT : when calculating the variable expense ratio, it's important that periods for expenses and premiums match, meaning that \textbf{if we use historical expenses (\$), then we use historical premiums (\$) as well.}
	
	
\section{Fixed Expenses Ratio}
	When having to find a fixed expense ratio, there is two methods possible, which we generally use depending on if the fixed expenses are trending at the same rate as the premiums or not. If they are (fixed expense trend = premium trend), then we would use the \textbf{Premium-based method}, if not (fixed expense trend $ \neq $ premium trend) we would use the \textbf{Exposure-based method.}
	
	\subsection{Premium-based method}
		As stated, this method generally assumes that the fixed expenses trend at the same rate as the premiums. This means that we can use historical premiums to calculate the fixed expense ratio, without going through the trouble of calculating on-level premiums. Hence, assuming that only general and other expenses are fixed, the definition of the fixed expense ratio is :
		\begin{equation*}
		\textbf{Fixed Expenses Ratio} = \frac{(\textbf{Fixed \% )(Other)}}{\textbf{Histo. Written Premium}} +\frac{\textbf{(Fixed \%)(General)}}{\textbf{Histo. Earned Premium}} 
		\end{equation*}
	
	
	\subsection{Exposure-based method}
		If expenses are trending at a different rate than premiums, this is the method to use. We calculate the expenses per exposure, that we trend to the futur rate effective period.
		
		The definition of the \emph{trending period} can be a little complex, since we usually make the assumption that general expenses are incurred at the average \emph{earned} premium date, while other expenses are incurred at the average \emph{written} premium date. Usually, the historical period will be in calendar year, making it so that the average written date and the average earned date is the same (the middle of the calendar year). But for the new rate effective period, which is a policy year, the written average date isn't equal to the average earned date : the average earned date is always 1/2 a policy term after written average date. This makes is so that \textbf{the trending period for general expenses is always a 1/2 policy term longer than the trending period for the other expenses.} 
		
		
		When we have the \textbf{total trended fixed expense per exposure}, which is the sum of all trended expenses per exposure, we can find the fixed expense ratio by dividing by the \textbf{average on-level and trended earned premiums}. This is the main difference from the Premium-based method, where we generally can use the historical premiums instead of on-level.
	
	
	
	
	








\chapter{Special Classification}

\section{Increased Limit Factors}


The increased limit factors ($ ILF $)are used by actuaries to price policies with different limits. The $ ILF $ is basically the differential for the "limit" variable : the $ ILF $ for the base limit is 1, and every other higher limit has $ ILF(H) > ILF_{B} $, where $ H > B  $. 

By making the assumption that frequency is the same regardless of the limit chosen (which isn't always the case), then we define the increased limit factor for limit $ H $ as 
\begin{align*}
ILF(H) = \frac{LAS(H)}{LAS(B)},
\end{align*}
where 
\begin{itemize}
	\item \emph{B} is the basic limit
	\item $ LAS(H) $ is the \emph{limited average severity} at limit $ H $. This is another way of saying severity limited at $ H $.
\end{itemize}

The calculations of the \emph{limited average severities} ($ LAS(i) $) differs whether we have access to ground-up losses or not. 

\subsection{Non-Censored (Ground-Up) Losses}
	Having access to ground-up losses makes the calculations really easy, as to calculate the $ LAS $ one only has to limit losses at the different limits and make the average. For example, let's say I have the following distribution of non-censored losses.

	\begin{tabular}{ccc}
		Size of Loss & Reported Claims & Losses (\$)\\
		\midrule
		$ [0, 100] $ & 500 & 35000\\
		$ [100, 500] $ & 250 & 80000\\
		$ [500,  \infty [ $ & 50 & 40000
	\end{tabular}

	Then we would have: 
	\begin{align*}
	LAS(100) &= \frac{35000 + 100(250 + 50)}{500 + 250 + 50} = 81.25,\\[10pt]
	LAS(500) &= \frac{35000 + 80000 +  500(50)}{500 + 250 + 50} = 175.00.
	\end{align*}
	This means that the increased limit factor at 500 is 
	\begin{align*}
	ILF(500) = \frac{LAS(500)}{LAS(100)} = \frac{175.00}{81.25} = 2.154.\\
	\end{align*}



\subsection{Censored Losses}
This is usually what we have to work with. We don't have all the ground-up losses, we only have losses that are limited at their respective limits. That makes harder to evaluate the \emph{limited average severity} for limits greater than the basic one, because\emph{ all the losses on policies that have the basic limit can't be used} (since they are limited at $ B $). To circumvent this problem, we add the severity for each layer of losses to \emph{LAS(B)} to find the other \emph{LAS}'s. In math, that means : 
\begin{align*}
LAS(H_{i}) = LAS(H_{i - 1}) + LAS(H_{i-1} < X \leq H_{i})\Pr(X > H_{i-1})
\end{align*}
where
\begin{itemize}
	\item $ H_{0} $ = B, the basic limit
	\item $ LAS(H_{i-1} < X \leq H_{i}) $ is the limited average severity for the losses between  $ H_{i-1} $ and $ H_{i} $. 
\end{itemize}
By the preceding definition, that means that in order to find the limited average severity for a high limit, the actuary needs to have previously calculated all \emph{LAS} for the lower limits. Here is an example. 

\begin{exemple}
	This example is inspired by the \#10 of the TIA Practice Exam 5 \#1. \\
	We want the 1000\$ \emph{ILF} using the information below, knowing that the basic limit is 100\$. 
	
	\begin{tabularx}{0.88\linewidth}{c|cc|cc|cc}
		\toprule
		\multicolumn{1}{c}{}& \multicolumn{2}{c}{100 Policy Limit} & \multicolumn{2}{c}{500 Policy Limit} & \multicolumn{2}{c}{1000 Policy Limit} \\
		Loss Amount & Losses & \# of Claims & Losses & \# of Claims & Losses & \# of Claims\\
		\midrule
		$ ]0, 100] $ 	& 22000 & 500 	& 5200	 	& 200 	& 9800 		& 350\\
		$ ]100, 500] $ 	&  		&  		& 22800 	& 120 	& 45850 	& 245\\
		$ ]500, 1000]$ 	&  		&  		& 		 	& 	 	& 12150 	& 18\\
		\bottomrule
	\end{tabularx}

	\begin{solution}
		As we want $ ILF(1000) $, we have to calculate \emph{LAS}'s for all the limits. First, we have : 
		\begin{align*}
		\mathbf{LAS(100)} 	&= \frac{22000 + 5200 + 9800 + 100(120 + 245 + 18)}{500 + 200 + 350 + 120 + 245 + 18}\\
					&= 52.547.
		\end{align*}
		Notice that for $ LAS(100) $, we can use all the losses of the book, since no losses in censored at a lower point than 100. 
		
		Next, we need to calculate $ LAS(100 < X \leq 500) $ in order to have $ LAS(500) $. In order to calculate this, we can't be using the losses coming from 100\$ limit policies. 
		\begin{align*}
		\mathbf{LAS(100 < X \leq 500)} 	&= \frac{22800 + 45850 + 500(18) \mathbf{- 100(120 + 245 + 18)}}{\mathbf{120 + 245 + 18}}\\
								&= 102.741
		\end{align*}
		Notice that since we want the severity \textbf{in the layer} $ ]100, 500] $, we have to subtract 100\$ to all of the losses. Also, since we only used the policies that have a limit higher than 100, we divided by $ 120 + 245 + 18 = 383 $ instead of by 1433 (total number of claims). Next we have to calculate the probability of having a claim higher than 100\$. 
		\begin{align*}
		\mathbf{\Pr(X > 100)} 	&= \frac{120 + 245 + 18}{\mathbf{200 + 350} + 120 + 245 + 18}\\
								&=0.4105
		\end{align*}
		Notice that we only took the claims for policies of limit 500\$ or 1000\$, since they are the only ones that can have losses over 100\$. With that information, we can calculate $ LAS(500) $.
		\begin{align*}
		\mathbf{LAS(500)} 	&= \mathbf{LAS(100) + LAS(100 < X \leq 500) \Pr(X > 100)}\\
							&=52.547 + 102.741 \times 0.4105\\
							&= 94.722
		\end{align*}
		
		Now, we only have to calculate $  LAS(500 < X \leq 1000) $ and  $\Pr(X > 500) $ in order to be able to calculate $ ILF(1000) $.
		\begin{align*}
		 \mathbf{LAS(500 < X \leq 1000)} &= \frac{12150 \mathbf{- 18(500)}}{18}\\
		 						&= 175.00\\[10pt] 
		 \mathbf{\Pr(X > 500)} 	&= \frac{18}{350 + 245 + 18}\\
		 				&= 0.0294
		\end{align*}
		With those, we now find
		\begin{align*}
		\mathbf{LAS(1000)} 	&= \mathbf{LAS(500) +  LAS(500 < X \leq 1000) \Pr(X > 500)}\\
					&= 94.722 + 175.00\times 0.0294\\
					&= 99.862
		\end{align*}
		and finally 
		\begin{align*}
		\mathbf{ILF(1000)} 	&= \mathbf{\frac{LAS(1000)}{LAS(100)}}\\
					&= \frac{99.862}{52.547}\\
					&= \fbox{\textbf{1.90041}}
		\end{align*}
	\end{solution}
\end{exemple}























\chapter{Credibility}

Credibility is a \emph{measure of the predictive value in a given application that the actuary attaches to a particular body of data}. The amount of credibility, $ Z $, should always meet the following three criteria : 
\begin{enumerate}[]
	\item $ 0 \leq Z \leq 1  $;
	\item $ Z $ should increase as the size of the risk increases;
	\item As the size of the risk increases, $ Z $ should increase at a decreasing rate.
\end{enumerate}
In the exam, if not stated otherwise, Z is always defined as : 
\begin{align*}
Z = \sqrt{\frac{Y}{\E[Y]}}
\end{align*}
where $ Y $ is the observed number of claims and $ \E[Y] $ is the standard for full credibility. Usually, the credible estimate is defined as 
\begin{align*}
\text{Estimate} = Z \times \text{Observed Experience} + (1-Z)\times \text{Complement of Credibility}.
\end{align*}
There are several methods of credibility described in the manual; as of right now they will not be included in this summary for lack of time. What we describe next are the several methods to calculate a proper \emph{complement of credibiliity} explained in the manual. 

A \emph{complement of credibility} should have those qualities : 
\begin{itemize}
	\item Accurate;
	\item Unbiased;
	\item Statistically independent from the base statistic;
	\item Available;
	\item Easy to compute;
	\item Logical in relation to the base statistic.
\end{itemize}
By accurate, we mean that its error variance should be as low as possible, while by unbiased mean that the complement should not be to high or to low on average. Basically, it should be precise and on target.  



\section{Loss Costs of a Larger Group (Including the Group being Rated)}

Goes with the name of the method, you choose a larger group that includes the group rated to be the complement. 

Next.

\section{Loss Costs of a Larger Related Group}

By contrast to the first method, this method uses a larger and related group as complement of credibility. This means that the larger group \emph{does not include} the group being rated, it's a separate but similar large group. For example, we could use the data from a larger and adjacent state.

Next.



\section{Rate Change from a Larger Group Applied to Present Rates}

The first two approaches are either not statistically independent or biased complements of credibility. This third approach mitigates the bias by using the subject group's experience with a factor from a larger group. The complement ($ C $) is written as : 
\begin{tcolorbox}[ams align*]
C = \text{Current Pure Premium of Subject} \times \left( \frac{\text{Larger Group \emph{Indicated} Pure Premium}}{\text{Larger Group \emph{Current} Pure Premium}} \right) 
\end{tcolorbox}
This complement is largely unbiased, accurate is the rate change (between indicated and current rates) is relatively small and logical. The independence depends on the size of the larger group relative to the subject group. 







\section{Harwayne's Method}
This method is to be used when the subject and the related experience have significantly different distributions. Also, \emph{the related groups must exclude the subject experience}. The easiest way to see the method is that it combines the experiences of a lot of groups, by adjusting all the groups so that they can be compared on the same base as the subject group. 

Let's illustrate the steps with an example. We have the following data, from which we will calculate a complement of credibility for Class 1 of State A, by using the data of Class B and C : 

\begin{tabular}{cccc}
	State & Class & Exposure & Pure Premium\\
	\midrule
	A & 1 & 100  & 2.50 \\
	& 2 & 125 & 4.00 \\
	\midrule
	B & 1 & 190 & 3.16 \\
	& 2 & 325 & 4.62\\
	\midrule
	C & 1 & 180 & 2.78 \\
	& 2 & 450 & 4.00 \\
\end{tabular}

\subsection*{Step 1 : Average pure premium the subject group}

This is the weighted average of the pure premium by the exposure, ie : 
\begin{align*}
\mean{L}_{A} 	&= \frac{\sum_{i = 1}^{2} X_{A,i}P_{A, i}}{\sum_{i = 1}^{2} X_{A,i}}\\
				&= \frac{(100)(2.50) + (125)(4.00)}{100 + 250}\\
				&= 3.33.
\end{align*}

\subsection*{Step 2 : Average pure premium of the related groups, based on the exposures of the subject group.}

In our examples, the related group are State $ B $ and \emph{C}. Based on the exposures of State \emph{A}, we have 
\begin{align*}
\hat{L}_{B} 	&= \frac{\sum_{i = 1}^{2} X_{A,i}P_{B, i}}{\sum_{i = 1}^{2} X_{A,i}}\\
				&= \frac{(100)(3.16) + (125)(4.62)}{100+125}\\
				&= 3.97
\end{align*}
and
\begin{align*}
\hat{L}_{C} 	&= \frac{\sum_{i = 1}^{2} X_{A,i}P_{C, i}}{\sum_{i = 1}^{2} X_{A,i}}\\
				&= \frac{(100)(2.78) + (125)(4.00)}{100+125}\\
				&= 3.46.
\end{align*}

\subsection*{Step 3 : Adjustment Factors}
The adjustment factors will be applied to the experience of each Class 1 from both State B and C, in order to adjust for the difference in pure premium with State A. The adjustment factors are calculated as : 
\begin{align*}
F_{B} 	&= \frac{\mean{L}_{A}}{\hat{L}_{B}}\\
		&= \frac{3.33}{3.97} = 0.84
\end{align*}
and 
\begin{align*}
F_{C} 	&= \frac{\mean{L}_{A}}{\hat{L}_{C}}\\
		&= \frac{3.33}{3.46} = 0.96
\end{align*}


\subsection*{Step 4 : Adjusted Pure Premium for Related Groups}
With the previously calculated adjustment factors, we now adjust the experience of each of the Class 1 for State \emph{B} and \emph{C}. 
\begin{align*}
\hat{L}_{B, 1} &= \mean{L_{B,1}} \times F_{B},\\
\hat{L}_{C, 1} &= \mean{L_{C,1}} \times F_{C}.\\
\end{align*}
Which gives 
\begin{align*}
\hat{L}_{B, 1} &=  3.16 \times 0.84 = 2.65,\\
\hat{L}_{C, 1} &= 2.78 \times 0.96 = 2.67.\\
\end{align*}


\subsection*{Step 5 : Complement of Credibility}

The last thing to do is to calculate the complement of credibility, which is the weighted average of the adjusted pure premiums previously calculated. In our example, that means : 
\begin{align*}
C 	&= \frac{\hat{L}_{B,1} \times X_{B,1} + \hat{L}_{C,1} \times X_{C,1}}{X_{B,1} + X_{C, 1}}\\
	&= \frac{2.65\times 190 + 2.67 \times 180}{190+180}\\
	&= 2.66
\end{align*}



\section{Trended Present Rates}
We use this method in the event where there is no larger group to have as a complement. The logic is that if there is no other complement, we might as well use the previous indicated change for credibility. There is two types of complement here, depending  on if we want to have a complement for a \emph{rate} or a \emph{rate change}. 

We define $ n $ as the length of time between \emph{the effective date of the last review and the effective date of the next rate change}. 

If we want credibility for a \emph{rate}, then the complement is :
\begin{align*}
C = \text{Present Rate}\times (\text{Loss Trend Factor})^{n} \times \frac{\text{Prior \emph{Indicated} Pure Premium}}{\text{Prior \emph{Implemented} Pure Premim}}
\end{align*}

As for a \emph{rate change}, the complement is calculated like :
\begin{align*}
C = \left(\frac{\text{Loss Trend Factor}}{\text{Premium Trend Factor}}\right)^{n} \left(\frac{\text{Prior \emph{Indicated} Pure Premium}}{\text{Prior \emph{Implemented} Pure Premim}}\right) 
\end{align*}






\section{Excess Ratemaking : Increased Limits Analysis}
To calculate complement of credibility for policies with limits (excess ratemaking), the manual presents 3 methods (4 actually, but the last one is to use a continuous distribution, whish is never going to be in an exam question). This is the first one. We calculate the complement for the layer of losses between $ A $ and $ (A + L) $. 
\begin{align*}
C = L_{A} \left( \frac{ILF_{A+L} - ILF_{A}}{ILF_{A}} \right) 
\end{align*}
\begin{itemize}
	\item $ L_{A} $ are the losses capped at A; 
	\item $ ILF_{i} $ is the increased limit factor for limit $ i $. 
\end{itemize}




\section{Excess Ratemaking : Lower Limits Analysis}
This method looks a lot like the first one. We still calculate the complement for the layer of losses between $ A $ and $ (A + L) $, the only difference is that we now use a lower limit as base, because \emph{we don't have access to the losses at the upper limit}, or because \emph{the data is to sparse}.   
\begin{align*}
C = L_{d} \left( \frac{ILF_{A+L} - ILF_{A}}{ILF_{d}} \right) 
\end{align*}
\begin{itemize}
	\item $ d \leq A $
	\item $ L_{d} $ are the losses capped at the lower limit $ d $; 
	\item $ ILF_{i} $ is the increased limit factor for limit $ i $. 
\end{itemize}


\section{Excess Ratemaking : Limits Analysis}

Again, we want a complement for the losses in the layer $ A $ and $ A + L $. It's calculated as : 
\begin{align*}
C = 
\begin{cases}
LR \times \sum_{\forall d \geq A} P_{d} \times \left( \frac{ILF_{\min(d, A+L)} - ILF_{A}}{ILF_{d}} \right) \quad & \text{if } d\geq A; \\
0 \quad & \text{otherwise}.
\end{cases}
\end{align*}
\begin{itemize}
	\item \emph{LR} = Expected Loss Ratio;
	\item  $ P_{d} $ = Total premium for policies with limit $ d $;
	\item $ ILF_{i} $ = Increased limit factor for limit $ i $.
\end{itemize}


















\chapter{Commercial Lines Rating}


\section{Experience Rating : ISO Rating Plan}

The formula for the experience modification is : 
\begin{align*}
\text{Mod} = Z \times \left(\frac{AER - EER}{EER}\right)
\end{align*}
where
\begin{itemize}
	\item \emph{AER} : Actual experience ratio;
	\item \emph{EER} : Expected experience ratio;
	\item \emph{Z} : Credibility Factor.
\end{itemize}

Usually, the actual experience ratio (\emph{AER}) is the harder component to calculate. It measures how the actual loss experience of the company was relative to the expected loss experience described in the ISO manual. It's define as 
\begin{align*}
AER = \frac{\text{Projected Ult. Losses and ALAE Limited at Basic Limit and MSL}}{\text{Company Subject Loss Cost}}
\end{align*}
The expected experience ratio (\emph{EER}) is basically a a measure of the expected deviation of the company's experience related to the expected loss experience described in the ISO manual. The \emph{EER} is defined as : 
\begin{align*}
EER = \frac{\text{Expected Ult. Losses and ALAE Limited at Basic Losses and MSL}}{\text{Company Subject Loss Cost}}
\end{align*}
Here are the steps of the methods to calculate the experience modification factor (Mod): 
\begin{enumerate}
	\item \textbf{Calculate Expected Losses at Basic Limit}\\
	They are defined as the insurer's expected \emph{Loss Ratio} times the earned premium for the basic limits policies. 
	\begin{align*}
	\text{Losses at Basic Limit} &= \text{Expected LR} \times \text{Premium at basic limit}\\
	\end{align*}
	
	\item  \textbf{De-trend the Basic Losses to Calculate the Company Subject Loss Cost (CSLC) per Year}\\
	Since the basic losses are trended to the present (because of the premiums), we have to de-trend them to make them more comparable to the actual losses from each years: 
	\begin{align*}
	CSLC_{i} = (\text{Basic Losses})_{i}(\text{De-Trend Factor})_{i}
	\end{align*}
	
	\item \textbf{Calculate the Total Company Subject Loss Cost}\\
	This is done by summing all of subject losses calculated in the previous step :
	\begin{align*}
	\text{Total Company Subject Loss Cost (\emph{CSLC})} = \sum_{i = 1}^{n} (\text{CSLC})_{i} 
	\end{align*}
	\emph{This is the denomimator for both the AER and the EER}.\\
	
	\item \textbf{If not given in the question, calculate the EER}\\
	
	\item \textbf{Calculate the Total Expected Development on the Subject Losses}\\
	This is the sum of the company subject loss cost per year times the \emph{EER} and the percentage of unreported claims.
	\begin{align*}
		\text{Expected Development} = \sum_{i=1}^{n}CSLC_{i}\times EER \times (\% \text{Unreported claims})_{i} 	
	\end{align*}
	\emph{This is used to calculate the Projected Ultimate Losses and ALAE, this numerator of the AER}. \\
	
	\item \textbf{Calculate the Projected Ult. Losses and ALAE}\\
	To do this, we want to cap the actual losses at the basic limit and add the expected development calculated in the previous step. \emph{With this, we have everything to calculate the AER}. \\
	
	\item \textbf{Calculate the Modification Factor}.
\end{enumerate}

Here is an example of a problem of that nature :
\begin{exemple}
	This is the \#15 of the TIA practice Exam 5 \#1. Given the following data for one year of experience, we want to calculate the experience modification factor for this company. 
	\begin{center}
		\begin{tabular}{ccc}
			& Loss & ALAE\\
			Claim 1 &15000 & 15000\\
			Claim 2 &35000 & 10000
		\end{tabular}
	\end{center}

	\begin{itemize}
		\item Basic limit : 25000\$
		\item Current basic limit premium : 100000\$
		\item De-trend factor : 0.85
		\item Expected \% of basic limit loss and ALAE unreported : 20\%
		\item Expected LR : 0.80
		\item We assume no Maximum Single Loss (MSL)
	\end{itemize}

\begin{solution}
	First, since we are told that there is no maximum single loss, the EER is equal to 1. We have to start by calculating the company subject loss cost. In order to do that, we have to de-trend the losses at basic limit, which are calculate as : 
	\begin{align*}
	\textbf{Losses at Basic Limit} &= \textbf{Expected LR} \times \textbf{Premium at basic limit}\\
	&= 0.7 \times 100 000\\
	&= 70 000
	\end{align*}
	So, after de-trending we have : 
	\begin{align*}
	\mathbf{CSLC} &= \textbf{Losses at Basic Limit} \times \textbf{De-Trend Factor}\\
	&= 70000 \times 0.85\\
	&= 59500
	\end{align*}
	
	Next, we want to calculate the expected development of losses : 
	\begin{align*}
	\text{Expected Dev.} &= CSLC \times \text{\% Unreported Claims}\\
	&= 59500\times 0.2
	&= 11900
	\end{align*}
	This will be used to calculate the projected ultimate losses and ALAE. Next, we have to calculate the actual losses, capped at the basic limit. 
	
	\begin{tabular}{cccc}
		& Loss & ALAE& Loss Capped at 25 k\$ + ALAE\\
		Claim 1 &15000 & 15000 & 30000\\
		Claim 2 &35000 & 10000 & 35000\\
	\end{tabular}

	This means that we have (30000 + 35000) = 65000\$ limited losses. With that, we have everything we need to calculate the \emph{AER} :
	\begin{align*}
	AER &= \frac{\text{Projected Ult. Losses and ALAE Limited at Basic Limit and MSL}}{\text{Company Subject Loss Cost}}\\
	&= \frac{65000 + 11900}{59500}\\
	&= 1.292
	\end{align*}
	Finally, knowing that the \emph{EER} is equal to 1 and that we have 80\% credibility, the experience modification factor is 
	\begin{align*}
	\text{Mod} &= Z \times \left(\frac{AER - EER}{EER}\right)\\
	&= 0.8 \left(\frac{1.292 - 1}{1} \right) \\
	&= 0.234
	\end{align*}
	So the Mod is a 23.4\% debit. 
\end{solution}
\end{exemple}













\chapter{Claims-Made Ratemaking}

Claims-made policies cover claims that are \emph{reported} during the effective policiy period, no matter when the claim occurred. The coverage trigger is the reporting of the claim. 

Upon the first purchase of a claims-made policy, the claim occurrence date is generally restricted to the start of the claims-made policy via a provision called the \emph{retroactive date}. This makes it so that the policy only covers claims that occurred after the retroactive date (is the retroactive date is the start of the first claims-made policy, then it only covers claims that happen in he first year).

Separate coverage called \emph{nose coverage} and \emph{tail coverage} can sometimes be purchased with claims-made policies to extend the coverage after the inception and after the expiry of the policy. This ensures that there is no gap in coverage. 

When a claims-made policy is purchased, it will be a first-year policy, as it usually has a retroactive date that corresponds with the start of the first effective period. \emph{The first-year claims-made policy will only cover claims that occur after the retroactive date} and that are reported during the policy term. 

At renewal, the insured will obtain a second-year claims-made policy. This policy still only covers claims that are reported during that second year, but theses claims could have occurred at any time after the initial retroactive date (at the start of the first year, usually). 

This logic goes on until the policy is considered, meaning that it covers all claims. This comes from the assumption that enough time has past from the first-year policy that all claims that could occur have occurred. 


As each consecutive claims-made policy effectively provides more coverage after each renewal, the premium will increase with each policy term (that's because after each renewal, the expected costs increase).This premium increase is usually computed using \emph{step-factors}. 































\part{Reserving (\emph{Freidland})}
	
	
	





\chapter{Case Outstanding Technique}

\section{Technique \#1}
	In order to use this technique, we need to have access to cumulative paid and reported claims triangles (from which you can calculate the case outstanding triangle). Here are the steps of the method: 
	\begin{enumerate}
		\item \textbf{Calculate the INCREMENTAL paid claims triangle.}\\
		
		\item \textbf{Calculate the case outstanding triangle.}\\
		
		\item \textbf{Calculate the ratio of \emph{incremental paid} to \emph{case oustanding}, and select a ratio per maturity.}\\
		The ratio is defined as :
		\begin{align*}
		\text{Ratio}_{i,j} = \frac{\text{Incremental Paid Claims}_{i,j}}{\text{Case Outstanding}_{i,j}}.
		\end{align*}
		This ratio corresponds to the proportion of case outstanding that was paid during the interval $ (j-12, j) $.
		
		When te triangle is complete, we select a ratio for each maturity. \textbf{These will be used to develop the incremental paid claim triangle. }\\
		
		
		\item \textbf{Calculate the development factors for the case outstanding triangle.}\\
		This works just like calculating the developing factors for reported or paid claims. We take the ratio of the case outstanding to the previous case outstanding. \textbf{We select a developing factor for each maturity, that will be used to develop the case outstanding to ultimate levels.} \\
		
		
		
		\item \textbf{Complete the case outstanding triangle}\\
		We multiply the previous case outstanding with the selected ratio for the current maturity. This will effectively complete the bottom part of the triangle. \\
		
		
		
		\item \textbf{Complete the incremental paid claim triangle}\\
		We complete the bottom part of the triangle. We use the freshly completed triangle of case outstanding with the ratio defined at step \#3. Since we now have case outstanding values for all cells $ (i,j) $, we can also calculated all the cells of the incremental paid triangle with the relationship : 
		\begin{align*}
		\text{Incremental Paid Claims}_{i,j} = \left(\text{Ratio}_{i,j}\right) \left(\text{Case Outstanding}_{i,j}\right).\\
		\end{align*}
		
		
		\item \textbf{Sum up the incremental paid claims for each accident year to have the ultimate cumulative paid claims.}\\
	\end{enumerate}



\section{Technique \#2}
This technique is only usable if \emph{there is no information on the reported and paid claims} for the company; \textbf{only the case outstanding are known}.

In this situation, the insurer can use industry benchmark to calculate a development factor for the case outstanding in order to find then ultimate \emph{unpaid} claims. The factor are always applied to the current case outstanding for each accident year. 
\begin{tcolorbox}[ams align*]
\text{Factor} = 1+ \frac{(\text{Rept CDF} - 1)(\text{Paid CDF})}{\text{Paid CDF} - \text{Rept CDF}} 
\end{tcolorbox}
The CDF's are all coming from industry benchmark. The ultimate unpaid claims are defined as:
\begin{align*}
\text{Ultimate Unpaid Claims} = 
\left( \begin{minipage}{0.14\linewidth}\centering
Current Case Outstanding
\end{minipage}\right)
\left(1+ \frac{(\text{Rept CDF} - 1)(\text{Paid CDF})}{\text{Paid CDF} - \text{Rept CDF}}  \right)
\end{align*}	
In order to calcultate the IBNR, we would subtract the current case outstanding to the ultimate unpaid claims. 



	
\chapter{Berquist-Sherman Techniques}

Theses techniques are used when an insurer has to deal with operational changes. Berquist and Sherman propose to ways : 
\begin{itemize}
	\item Use data \emph{selection} to isolate or neutralize the impact of the changes;
	\item Adjust the data to restate historical data as if the changes never occurred; 
\end{itemize}
	
The first option has more to do with making wise choices considering the situation, but doesn't require a specific methodology. The second option however does, and this is what is known as the Berquist-Sherman techniques. Theses techniques can be used to adjust triangles for changes in \textbf{claim settlement rates} and/or \textbf{case reserve adequacy}.

\section{Claim Settlement Rates Changes}
	 
	The assumptions of this method is that changes in the disposal rates are only due to changes in settlement rates, not due to things like changes in prioritization between small and large claims or in the rate of reporting. 
	
	Here are the steps of this technique : 
	\begin{enumerate}
		\item \textbf{Calculate the disposal rate triangle}. \\
		As we remember, disposal rates for accident year \emph{i} and age \emph{j} ($ D_{i,j} $)are defined as : 
		\begin{align*}
		D_{i,j} = \frac{\text{\# of Closed Claim Count}_{j}}{\text{\# of Ultimate \emph{Reported} Claim Count}_{i}}.
		\end{align*}
		
		
		
		
		
		\item \textbf{From the disposal rate triangle, select disposal rates along one of the diagonals}.\\
		Usually, we choose the latest disposal rate (the latest diagonal of the triangle). We will denote the selected disposal rate as $ \hat{D}_{j}$, where $ j $ can be all of the maturities of the triangle. 
		
		
		
		
		
		
		\item \textbf{Create the adjusted paid claims triangle.} 
		
		To do this, we need to determine a relationship between disposal rated of paid claim amount. This is usually done by regression. On the exam, we should expect linear or exponential regression to be used. If the relationship is linear, linear interpolation can be used. 
		
		For example, let's say we have the two following triangles : \\
	
		\begin{tabularx}{0.75\textwidth}{ccccclcccc}
			\toprule
			\textbf{Accident} & \multicolumn{4}{c}{\textbf{Disposal Rates}} & & \multicolumn{4}{c}{\textbf{Avg  Paid Claims}}\\
			\textbf{Years} & 12 & 24 & 36 & 48 & & 12 & 24 & 36 & 48  \\
			\midrule
			2010 & 0.400 & 0.730 & 0.850 & \textbf{0.920} & &  200 & 350 & 450 & 520  \\
			2011 & 0.400 & 0.667 & \textbf{0.833} & & & 250 & 400 & 550 & \\
			2012 & 0.357 & \textbf{0.679} & & & & 240 & 420 & & \\
			2013 & \textbf{0.367} & & &  & & 310 & & & \\
			\bottomrule
		\end{tabularx}\\
		
		The amount of paid claims we interpolate between depend on whether the historical disposal rate $ D_{i,j} $ is higher or lower than the \emph{selected} disposal rate $ \hat{D}_{j} $. Let's assume that we can use linear interpolation. We will show how to use exponential regression between two points later. 
		\begin{itemize}
			\item \textbf{If} $ \mathbf{D_{i,j} < \hat{D}_{j}} $, just like for AY2012 at maturity 12 where $ 0.357 < 0.367 $, then we will want to increase the cumulative paid claims at AY2012 maturity 12. The logic is that we want to bring $ D_{2012,12} $ closer to the level of $ \hat{D}_{12} $. In order to increase the level of $ D_{i,j} $, we will interpolate the cumulative paid claims $ PC_{i,j} $ with the paid claims from the next maturity. \\
			
			In our example, that means interpolate $ PC_{2012, 12} $ with $ PC_{2012, 24} $. So we'd have 
			\begin{align*}
			\text{Adjusted }C_{(2012, 12)} &= \left(\frac{\hat{D}_{12} - D_{2012, 12}}{D_{2012, 24} - D_{2012, 12}}\right)PC_{2012, 24} + \left(\frac{D_{2012, 24} - \hat{D}_{12}}{D_{2012, 24} - D_{2012, 12}}\right)PC_{2012, 12}\\
			&= PC_{2012, 12} + \left(PC_{2012, 24} - PC_{2012, 12} \right)\left( \frac{\hat{D}_{12} - D_{2012, 12}}{D_{2012, 24} - D_{2012, 12}}\right)\\
			&= 240 + (420 - 240)\left(\frac{0.367 - 0.357}{0.679 - 0.357}\right)\\
			&= 245
			\end{align*}
		
			\item \textbf{Else if} $ \mathbf{D_{i,j} > \hat{D}_{j}} $, just like for AY2010 maturity 12 where $ 0.400>0.367 $, then the interpolation has to decrease the amount of paid claims. Hence, we interpolate between the $ PC_{i,j} $ and the paid claims of the \emph{previous} maturity. \\
			
			In our example with AY2010 and maturity 12, that means interpolate between $ PC_{2010, 0} = 0 $ and $ PC_{2010, 12} = 200 $. The adjusted paid claims would then be 
			\begin{align*}
			\text{Adjusted }C_{(2010, 12)} &= \left(\frac{\hat{D}_{12} - 0}{D_{2010, 12} - D_{2010, 0}}\right)PC_{2010, 12} + \left(\frac{D_{2010, 12} - \hat{D}_{12}}{D_{2010, 10} - 0}\right)PC_{2010, 0}\\
			&= PC_{2010, 0} + \left(PC_{2010, 12} - PC_{2010, 0} \right)\left( \frac{\hat{D}_{12} - D_{2012, 0}}{D_{2012, 12} - D_{2012, 0}}\right)\\
			&= 0 + (200 - 0)\left(\frac{0.367 - 0}{0.400 - 0}\right)\\
			&= 183
			\end{align*}
		\end{itemize}
	
	
	Instead of a linear interpolation,  we could have had to use exponential regression between two points to find the adjusted paid claims. Here's how to proceed in that situation. We start with the general equation \fbox{$ \hat{Y}_{i,j} = a_{i,j}e^{b_{i,j}X_{i,j}}, $} where $ X $ is the closed claim count at $ (i,j) $, $ Y $ is the adjusted paid claims at $ (i,j) $ and \emph{a} and \emph{b} are the regression parameters. \\
	
	The same rules apply regarding if we interpolate between the paid claim at previous or next maturity (if $ D_{i,j} < \text{or} > \hat{D}_{j} $), but these now apply as to the values used to calculate the \emph{b} parameter. Assuming that we interpolate to the next maturity, the \emph{b} parameter would be : 
	\begin{align*}
	b_{i,j} = \frac{\ln(PC_{i, j+12}) - \ln(PC_{i, j})}{nC_{i, j + 12} - nC_{i,j}}
	\end{align*}
	where $ nC_{i,j} $ is the number of closed claims at $ (i,j) $. 
	
	After finding each $ b_{i,j} $ parameter, we would find the $ a_{i,j} $ parameters using the culumative paid claims and the number of closed claims at $ (i,j) $. If $ Y_{i,j} $ is the cumulative paid claims at $ (i,j) $, then we have 
	\begin{align*}
	a_{i,j} = \frac{Y_{i,j}}{e^{b_{i,j}X_{i,j}}}
	\end{align*}
 	With both parameters, we can then calculate the adjusted paid claims, with \fbox{$ \hat{Y}_{i,j} = a_{i,j}e^{b_{i,j}X_{i,j}} $}.\\
	
	
	\item \textbf{When the adjusted paid claims triangle is complete, the last step is to calculate the ultimate claims using the development technique.} \\
	

	\end{enumerate}
	
 
	

	
	
	\section{Case Adequacy Adjustment}
	
	The last section adjusted \emph{paid} claims. In order to makes adjustment to \emph{reported} claims triangle, we need to determine whether there have been changes in case adequacy, and if so, how to \emph{adjust the case outstanding} for these changes. Here are the steps of this technique :
	\begin{enumerate}
		\item \textbf{Calculate the adjusted \emph{open} claim count.}\\
		To calculate the adjusted \emph{open} claim count, we first need to adjust the closed claim count. \\
		
		We calculate the \textbf{adjusted \emph{closed} claim count} by multiplying the \textbf{disposal rates} by the \textbf{projected unadjusted \emph{reported} claim count} (which we usually get in the question). 
		\begin{align*}
		\left(\begin{minipage}{0.18\linewidth}\centering
		Adjusted \emph{Closed} Claims Count
		\end{minipage}\right)_{i,j} = 
		\left(\begin{minipage}{0.095\linewidth}\centering
		Disposal Rate
		\end{minipage}\right)_{j}
		\left(\begin{minipage}{0.245\linewidth}\centering
		Projected Unadjusted \emph{Reported} Claim Count
		\end{minipage}\right)_{i}
		\end{align*}

		Then, we calculate the \textbf{adjusted \emph{open} claim count} by subtracting the adjusted closed claim count to the reported claim count. 
		\begin{align*}
		\left(\begin{minipage}{0.17\linewidth}\centering
		Adjusted \emph{Open} Claim Count
		\end{minipage}\right)_{i,j} = 
		\left(\begin{minipage}{0.18\linewidth}\centering
		Reported Claim Count
		\end{minipage}\right)_{i,j} - 
		\left(\begin{minipage}{0.17\linewidth}\centering
		Ajusted \emph{Closed} Claim Count
		\end{minipage}\right)_{i,j}\\
		\end{align*}
		
		
		\item \textbf{Calculate the severity trend observed in the average paid claim.}\\
		On the exam, we most likely habe the severity trend given from the question. Otherwise, we calculate this trend with the average unadjusted paid claim triangle, and use regression or \% of change to evaluate the change.\\
		
		
		
		\item \textbf{Calculate the average case reserve triangle.}\\
		We calculated the average case reserve (avg $ CR_{i,j} $) by dividing \emph{reported claims} minus \emph{paid claims} by the \emph{adjusted open claim counts}.
		\begin{align*}
		\text{avg } CR_{i,j} = \frac{\text{Reported Claims} - \text{Paid Claims}}{\text{Adjusted \emph{Open} Claim Count}}\\
		\end{align*}
		
		
		\item \textbf{Calculate the adjusted average case reserves.} \\
		Using the severity trend calculated in the first step, we calculate the adjusted average case reserve by de-trending the latest case outstanding of each accident year by the severity trend. If we write  the latest average case reserve as (avg $ CR_{i,j}^{S} $), then we calculate the adjusted average case reserve as : 
		\begin{align*}
		\text{Adjusted avg } CR_{i,j} = \frac{\text{avg }CR_{i,j}^{S}}{(\text{Sev Trend})^{\text{Latest Period} - i}}
		\end{align*}
		
		For example, let's say we have a severity trend of 10\% and the following average case reserve triangle, we would have the following adjusted average case reserve:\\
		
		\begin{tabularx}{0.9\textwidth}{cccclccc}
			\toprule
			\textbf{Accident} & \multicolumn{3}{c}{\textbf{Avg Case Reserve}} & & \multicolumn{3}{c}{\textbf{Adj Avg Case Reserve}}\\
			\textbf{Years} & 12 & 24 & 36 & & 12 & 24 & 36  \\
			\midrule
			2011 & 1000 & 3000 & \textbf{5000} & & $ 1136 = 1375/1.10^{2} $ & $ 3000 = 3000/1.10^{1} $ & \textbf{5000} \\
			2012 & 1100 & \textbf{3300} & & & $ 1250 = 1375/1.10^{1} $ & \textbf{3300} & \\
			2013 & \textbf{1375} & &  & & \textbf{1375} & & \\
			\bottomrule
		\end{tabularx}\\[10pt]
		
		
		
		\item \textbf{Calculate adjusted average \emph{reported} claims.}\\
		We calculate the adjusted average reported claims by  multiplying the adjusted case reserve times the open claims count and adding the cumulative paid claims  :
		\begin{tcolorbox}[ams align*]
		\begin{minipage}{0.22\linewidth}\centering
			Adjusted Average Reported Claims
		\end{minipage} = 
		\left(\begin{minipage}{0.18\linewidth}\centering
			Adjusted Case Reserve
		\end{minipage}\right)
		\left(\begin{minipage}{0.15\linewidth}\centering
			Open Claim Count
		\end{minipage}\right) + 
		\begin{minipage}{0.18\linewidth}\centering
			Cumulative Paid Claim
		\end{minipage}
		\end{tcolorbox}
		
		
		IMPORTANT: If there is no changes in the settlement rates, there is no adjustment to make on the paid claims. If there are settlement rates changes, then we have to make both adjustment (case outstanding and paid claims). \\
	
	
	
		\item \textbf{When the adjusted reported claims triangle is complete, the last step is to calculate the ultimate claims using the development technique.} 
	\end{enumerate}
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
\chapter{ALAE Estimation}

There are 3 common approaches to estimating ALAE : 
\begin{enumerate}
	\item Combine the ALAE to the estimate claims, and estimate both together (this is what was done throughout most of the manual). This method may not be accurate if the ALAE have very different development pattern than the claims.
	\item With only ALAE, use the development technique (or any other techniques) on a ALAE triangle
	\item Develop a \textbf{\emph{ratio triangle}} of the \emph{paid ALAE to paid claims} or \emph{reported ALAE to reported claims}. 
\end{enumerate}
	
The first two approaches don't have to be elaborated on any further, so we discuss the ratio approach in the rest of the chapter. 
	
With the triangle ratio, there is usually two ways of evaluating development : \emph{multiplicatively} (as we've done for any other techniques) or \emph{additively}. Developing additively is usually more stable if the ratios are very small at early maturities. 
	
Here is an example using both additive and multiplicative development for the ratios. 

\begin{tabularx}{\textwidth}{c|cccc|ccc}
	Accident & \multicolumn{3}{c}{Cum. Paid Claims} & Ult. &  \multicolumn{3}{c}{Cum. Paid ALAE}\\
	Years & 12 months & 24 months  & 36 months  & Claims &  12 months  & 24 months  & 36 months   \\
	\midrule
	2011 & 5039 & 5651 & 5651 & 5651 &  701 & 1498 & 1498 \\
	2012 & 5031 & 5621 & & 5621 &  665 & 1522 & \\
	2013 & 4909 & &  & 5493 & 675 & & \\
\end{tabularx}\\

With both tables, we calculate the ratios for each cell.

\begin{tabularx}{0.51\textwidth}{c|ccc}
	Accident & \multicolumn{3}{c}{Ratio Paid ALAE / Paid Claims} \\
	Years & 12 months & 24 months  & 36 months   \\
	\midrule
	2011 & 0.139 & 0.265 & 0.265  \\
	2012 & 0.132 & 0.276 &  \\
	2013 & 0.138 & &  \\
\end{tabularx}\\
	
Next, we evaluate the development either additively or multiplicatively. 

\begin{tabularx}{0.651\textwidth}{c|ccc|ccc}
	Accident & \multicolumn{3}{c}{Additive}  &  \multicolumn{3}{c}{Multplicative}\\
	Years & 12-24 & 24-36 & 36-Ult   &  12-24 & 24-36 & 36-Ult   \\
	\midrule
	2011 & 0.126 & 0.000 &  &  1.906  & 1.000 &  \\
	2012 & 0.144 &  & & 2.089 &  & \\
	\midrule
	Average & 0.135 & 0.000 & & 1.997 & 1.000 & \\
	Selected & 0.135 & 0.000 & 0.000 & 1.997 & 1.000 & 1.000\\
	Cum. Factor & 0.135 & 0.000 & 0.000 & 1.997 & 1.000 & 1.000\\
\end{tabularx}\\
	
With those development factors, we can calculate the ultimate ALAE by \emph{developing the current ratios to their ultimate level} and then using the ultimate ratios with ultimate claims to have the ultimate ALAE. For example, for accident year 2013 using the additive factors: 
\begin{align*}
\textbf{Ultimate Ratio} &= 0.138 + 0.135 \\&= 0.272\\[7pt]
\textbf{Ultimate ALAE} &= \textbf{Ultimate Claims}\times\textbf{Ultimate Ratio}\\
&= 0.272 \times 5493\$\\
&= 1497\$
\end{align*}
	
	
	
	
	
	
	

\chapter{ULAE Estimation}


\section{Dollar-Based Techniques}

\begin{tcolorbox}
\textbf{For this section, we have to know the following notation : }
	\begin{description} 
		\item[$ \mathbf{M_{i}} $:] Paid ULAE for calendar year $ i $ ;
		\item[$ \mathbf{W_{i}} $:] Ratio of ULAE to claims for calendar year $ i $ ;
		\item[$ \mathbf{W^{*}} $:] Selected ratio of ULAE to claims ;
		\item[$ \mathbf{B_{i}} $:] Claim basis for calendar year $ i $ ;
		\item[$ \mathbf{L_{i}} $:] Ultimate claims for calendar year $ i $ ;
		\item[$ \mathbf{R_{i}} $:] Ultimate cost of claims reported (ie. opened) during calendar year $ i $ ;
		\item[$ \mathbf{P_{i}} $:] Paid claims during calendar year $ i $ ;
		\item[$ \mathbf{C_{i}} $:] Ultimate cost of claims closed during calendar year $ i $ ;
		\item[$ \mathbf{U_{1}} $:] Percent of ultimate ULAE spent on opening (reporting) claims ;
		\item[$ \mathbf{U_{2}} $:] Percent of ultimate ULAE spent on maintaining (paying) claims  ;
		\item[$ \mathbf{U_{3}} $:] Percent of ultimate ULAE spent on closing claims ; \\
	\end{description}

The relationship of the paid ULAE to claim costs is then defined as : 
\begin{align*}
\mathbf{M_{i}= W_{i}B_{i} = W_{i}\left(U_{1}R_{i} + U_{2}P_{i} + U_{3}C_{i}\right)}.
\end{align*}
As seen in the previous definition, we define the ration $ \mathbf{W_{i}} $ as $ \mathbf{W_{i} = M_{i}/B_{i}} $.
\end{tcolorbox}




\subsection{Paid-to-Paid (Classical Technique)}
	
	The assumptions of this method is that the ratio is generally stable through time and that the cost of future claims management activity will be proportional to the IBNR and case outstanding. Hence, in this technique, selected ratio of ULAE to claims ($ \mathbf{W^{*}} $) is estimated using the ratios ($ \mathbf{W_{i}} $) of \emph{paid ULAE} to \emph{paid claims}:
	\begin{align*}
	W_{i} = \frac{M_{i}}{B_{i}} = \frac{M_{i}}{P_{i}}
	\end{align*}
	With all of the ratios $ W_{i} $, we select $ \mathbf{W^{*}} $. 
	
	The technique assumes that half of the ULAE are sustained when a claim is opened, while the other half is sustained when it is closed. Hence, \emph{we apply 50\% of the ratio to case outstanding} (since the first half of the expenses is already incurred) and \emph{100\% of the ratio to the IBNR} (since it's not yet reported, no expenses has been incurred). This means :
	\begin{align*}
	\text{Unpaid ULAE} = W^{*}\times\left[50\%(\text{Case Outstanding + IBNER}) + 100\%(\text{Pure IBNR}) \right]
	\end{align*}
	Usually, the split between IBNR and IBNER isn't available in the data. In that case, we assume IBNER = 0. 
	
	The classical approach does not work well for long-tail lines of business, in times when ULAE inflation rates differ	from claims inflation rates, when the insurer is significantly growing or shrinking, or when the 50/50 assumption is not appropriate.\\
	
	
	
	
	
	
\subsection{Kittel Technique}
	
	The only difference between the Kittel approach and the classical approach is in the estimation of the claims basis ($ \mathbf{B_{i}} $). Instead of using only the paid claims, the Kittel recognizes that the steady-state assumption ($ R = P $) is \emph{flawed for a growing or shrinking book}.
	
	Instead, this technique assume that the claim basis for each calendar year ($ \mathbf{b_{i}} $) is the average of the \emph{incurred claims} and the \emph{paid claims} for each year (meaning that $ U_{1} = 0.5, U_{2} = 0.5 $ and $ U_{3} = 0 $). We define the \emph{incurred claims} like :
	\begin{align*}
	\text{Incurred Claims} &= \text{Paid Claims} + \text{Change in TOTAL Reserve}\\
	\textbf{Incurred Claims} &= \textbf{Paid Claims} + \textbf{(Case Outstanding + IBNR)}
	\end{align*}
	
	Using this definition, can define the claim basis per calendar year ($ \mathbf{b_{i}} $) as 
	\begin{align*}
	B_{i} = 0.5(\text{Incurred Claims})_{i} + 0.5(\text{Paid Claims})_{i}
	\end{align*}
	and the ratios $ \mathbf{W_{i}} $ as 
	\begin{align*}
	W_{i} = \frac{M_{i}}{B_{i}} = \frac{M_{i}}{0.5(\text{Incurred Claims})_{i} + 0.5P_{i}}.
	\end{align*} 
	
	With the ratios $ \mathbf{W_{i}} $, we can select $ \mathbf{W^{*}} $ using the same methods as with the classical technique. At this point, the Kittel technique goes back to be equivalent to the classical technique. \emph{We apply 50\% of the ratio to case outstanding and IBNER} (since the first half of the expenses is already incurred) and \emph{100\% of the ratio to the IBNR}, meaning that we define unpaid ULAE as :
	\begin{align*}
	\text{Unpaid ULAE} = W^{*}\times\left[50\%(\text{Case Outstanding + IBNER}) + 100\%(\text{Pure IBNR}) \right]
	\end{align*}
	
	Just like the classical technique, the Kittel approach still does not work well when the 50/50 assumption is not appropriate or when ULAE	inflation rates differ from claims inflation rates.\\
	
	
	
	
	
	
	
\subsection{Generalized Approach}
	Here, we define the claim basis $ \mathbf{B_{i}} $ as the proportion of all three types of claims : \emph{reported, paid} and \emph{closed}. In math, that means
	\begin{align*}
	B_{i} = U_{1}R_{i} + U_{1}P_{i} + U_{3}C_{i},
	\end{align*}
	which also means that we define $ \mathbf{W_{i}} $ as 
	\begin{align*}
	W_{i} = \frac{M_{i}}{U_{1}R_{i} + U_{1}P_{i} + U_{3}C_{i}}
	\end{align*}
	
	After choosing a selected ratio $ \mathbf{W^{*}} $, there are 3 ways to estimate the unpaid ULAE, that all use the ultimate claims per accident ear ($ \mathbf{L_{i}} $) in different fashion.
	
	\begin{enumerate}
		\item \textbf{Expected claims approach}:\\
		In this method, we define the unpaid ULAE as
		\begin{align*}
		\text{Unpaid ULAE} = (W^{*} \times L_{i}) - M_{i}
		\end{align*}
		This method isn't the most responsive to changes in the ULAE to claim ratio.\\
		
		
		\item \textbf{Bornhuetter-Ferguson approach}\\
		In this method, we define the unpaid ULAE as
		\begin{align*}
		\text{Unpaid ULAE} = W^{*} \times (L_{i} - B_{i})
		\end{align*}
		This is the preferred method of the manual. Using a weigthed average of $ W_{i} $ for the selection of $ W^{*} $, this gives the same result as the expected claim approach. \\
		
		
		\item \textbf{Development approach}\\
		In this method, we define the unpaid ULAE as
		\begin{align*}
		\text{Unpaid ULAE} = M_{i}\times (\frac{L_{i}}{B_{i}} - 1)
		\end{align*}
		This approach is flawed for two reasons. First, it can be overly responsive to random fluctuations in ULAE emergence. Second, it is practically difficult to quantify ULAE on a accident year basis as we would need $ M $ to correspond the accident years in \emph{L}.
	\end{enumerate}





\subsection{Simplified Generalized Approach}	
	Since it may be difficult to estimate R and C for use in the generalized formula, the manual provides a simplification to the generalized approach to estimate the claims basis:
	\begin{itemize}
		\item \emph{R} is approximated using the accident year ultimate claims (\emph{L}) when calculating \emph{W}. \emph{Only when calculating \emph{W}, \textbf{not in the calcuations of the unpaid ULAE}}. 
		\item We assume that no expense is required to close claims, and so $ U_{3} = 0$ and \emph{C} is no longer needed. 
	\end{itemize}
	After those simplifications, and after having selected $ \mathbf{W^{*}} $, we calculate the unpaid ULAE as :
	\begin{align*}
	\text{Unpaid ULAE} &= W^{*} \times \left[ L_{i} - U_{1}R_{i} - U_{2}P_{i}\right]\\
	&= W^{*} \times \left[ U_{1}(L_{i} - R_{i}) - U_{2}(L_{i} - P_{i})\right]\\
	&= \mathbf{W^{*} \times \left[ U_{1}(\textbf{Pure IBNR}) + U_{2}(\textbf{Case Oustanding} + \textbf{IBNER}+ \textbf{Pure IBNR})\right]}\\
	&= \mathbf{W^{*} \times \left[ \textbf{Pure IBNR} + U_{2}(\textbf{Case Oustanding} + \textbf{IBNER})\right]}
	\end{align*}
	
	This last definition implies that $ (L_{i} - P_{i}) = (\text{Case Oustanding} + \text{IBNER}+ \text{Pure IBNR}) $ and that $ (L_{i} - R_{i}) = \text{Pure IBNR} $.
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
\end{document} 
